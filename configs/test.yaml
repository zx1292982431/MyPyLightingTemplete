# pytorch_lightning==2.3.0
seed_everything: true
trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: null
  logger: null
  callbacks: null
  fast_dev_run: false
  max_epochs: null
  min_epochs: null
  max_steps: -1
  min_steps: null
  max_time: null
  limit_train_batches: null
  limit_val_batches: null
  limit_test_batches: null
  limit_predict_batches: null
  overfit_batches: 0.0
  val_check_interval: null
  check_val_every_n_epoch: 1
  num_sanity_val_steps: null
  log_every_n_steps: null
  enable_checkpointing: null
  enable_progress_bar: null
  enable_model_summary: null
  accumulate_grad_batches: 1
  gradient_clip_val: null
  gradient_clip_algorithm: null
  deterministic: null
  benchmark: null
  inference_mode: true
  use_distributed_sampler: true
  profiler: null
  detect_anomaly: false
  barebones: false
  plugins: null
  sync_batchnorm: false
  reload_dataloaders_every_n_epochs: 0
  default_root_dir: null
model:
  arch:
    class_path: models.arch.SpatialNet.SpatialNet
    init_args:
      dim_input: 2
      dim_output: 2
      num_layers: 8 # 12 for large
      encoder_kernel_size: 5
      dim_hidden: 96 # 192 for large
      dim_ffn: 192 # 384 for large
      num_heads: 4
      dropout: [0, 0, 0]
      kernel_size: [5, 3]
      conv_groups: [8, 8]
      norms: ["LN", "LN", "GN", "LN", "LN", "LN"]
      dim_squeeze: 8 # 16 for large
      num_freqs: 129
      full_share: 0
  channels: [0,]
  ref_channel: 0
  stft:
    class_path: models.io.stft.STFT
    init_args:
      n_fft: 256
      n_hop: 128
  loss:
    class_path: models.io.loss.Loss
    init_args:
      loss_func: models.io.loss.neg_si_sdr
      pit: False
  norm:
    class_path: models.io.norm.Norm
    init_args:
      mode: none
  optimizer:
  - Adam
  - lr: 0.001
  lr_scheduler:
  - ReduceLROnPlateau
  - mode: min
    factor: 0.5
    patience: 5
    min_lr: 0.0001
  metrics:
  - SDR
  - SI_SDR
  - WB_PESQ
  - WB_PESQ
  - eSTOI
  - DNSMOS
  - STOI
  mchunk: null
  val_metric: loss
  write_examples: 200
  sample_rate: 16000
  ensemble: null
  compile: false
  exp_name: exp
  reset: null
early_stopping:
  enable: false
  monitor: val/metric
  min_delta: 0.1
  patience: 10
  verbose: false
  mode: max
  strict: true
  check_finite: true
  stopping_threshold: null
  divergence_threshold: null
  check_on_train_epoch_end: null
  log_rank_zero_only: false
model_checkpoint:
  dirpath: null
  filename: epoch{epoch}_metric{val/metric:.4f}
  monitor: val/metric
  verbose: false
  save_last: true
  save_top_k: -1
  save_weights_only: false
  mode: max
  auto_insert_metric_name: false
  every_n_train_steps: null
  train_time_interval: null
  every_n_epochs: 1
  save_on_train_epoch_end: null
  enable_version_counter: true
progress_bar:
  refresh_rate: 1
  leave: false
  theme:
    description: white
    progress_bar: '#6206E0'
    progress_bar_finished: '#6206E0'
    progress_bar_pulse: '#6206E0'
    batch_progress: white
    time: grey54
    processing_speed: grey70
    metrics: white
    metrics_text_delimiter: ' '
    metrics_format: .3f
  console_kwargs:
    force_terminal: true
    no_color: true
    width: 200
learning_rate_monitor:
  logging_interval: epoch
  log_momentum: false
  log_weight_decay: false
model_summary:
  max_depth: 2
ckpt_path: null
